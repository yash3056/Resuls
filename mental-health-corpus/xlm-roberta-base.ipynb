{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"999aaf37-c727-4c1b-8151-7fe2df254c75","_cell_guid":"e9be33da-844c-4110-8c3f-a71bb7b55e91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:29.878861Z","iopub.execute_input":"2024-08-10T15:15:29.879267Z","iopub.status.idle":"2024-08-10T15:15:31.821265Z","shell.execute_reply.started":"2024-08-10T15:15:29.879237Z","shell.execute_reply":"2024-08-10T15:15:31.820272Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mental-health-corpus/mental_health.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\n## nltk doesn't work on kaggle\n# import nltk\n# from nltk.tokenize import word_tokenize\n# from nltk.stem import WordNetLemmatizer\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"d3afe6ca-447d-4809-b0c7-7633b55991db","_cell_guid":"0f636fa6-e0c3-4187-abd2-d4141cc02386","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:31.822855Z","iopub.execute_input":"2024-08-10T15:15:31.823230Z","iopub.status.idle":"2024-08-10T15:15:40.175778Z","shell.execute_reply.started":"2024-08-10T15:15:31.823203Z","shell.execute_reply":"2024-08-10T15:15:40.174728Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Download necessary NLTK data\n# nltk.download('punkt')\n# nltk.download('wordnet')\n# nltk.download('omw-1.4')","metadata":{"_uuid":"3f561c33-f787-40b5-a254-a877d73604b4","_cell_guid":"f852300f-5891-4aed-b673-bea96f5e06c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:40.176868Z","iopub.execute_input":"2024-08-10T15:15:40.177268Z","iopub.status.idle":"2024-08-10T15:15:40.181428Z","shell.execute_reply.started":"2024-08-10T15:15:40.177242Z","shell.execute_reply":"2024-08-10T15:15:40.180535Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mental-health-corpus/mental_health.csv')\ndf.head()","metadata":{"_uuid":"33ea452e-c7c0-4b93-a285-bb961a8a9dfb","_cell_guid":"fc6ba930-9c12-4052-bbf9-9c1f0c6d4c64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:40.183886Z","iopub.execute_input":"2024-08-10T15:15:40.184606Z","iopub.status.idle":"2024-08-10T15:15:40.528489Z","shell.execute_reply.started":"2024-08-10T15:15:40.184574Z","shell.execute_reply":"2024-08-10T15:15:40.527602Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  dear american teens question dutch person hear...      0\n1  nothing look forward lifei dont many reasons k...      1\n2  music recommendations im looking expand playli...      0\n3  im done trying feel betterthe reason im still ...      1\n4  worried  year old girl subject domestic physic...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dear american teens question dutch person hear...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nothing look forward lifei dont many reasons k...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>music recommendations im looking expand playli...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>im done trying feel betterthe reason im still ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>worried  year old girl subject domestic physic...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_punctuation_and_emojis(text):\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n\n    # Remove emojis\n    emoji_pattern = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n        u\"\\U0001FA00-\\U0001FA6F\"  # Extended Symbols and Pictographs\n        u\"\\U0001FAB0-\\U0001FABF\"  # Additional animals & nature\n        u\"\\U0001FAC0-\\U0001FAFF\"  # Additional people & body\n        u\"\\U0001FAD0-\\U0001FAFF\"  # Additional food & drink\n        u\"\\U00002000-\\U0000206F\"  # General Punctuation (includes â€¼)\n        u\"\\U00002300-\\U000023FF\"  # Miscellaneous Technical\n        u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n        \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n\n    return text\n\ndef process_text(text):\n    # Convert to lowercase\n    text = text.lower()\n\n    # Remove punctuation and emojis\n    text = remove_punctuation_and_emojis(text)\n\n#     # Tokenize the text\n#     tokens = word_tokenize(text)\n\n#     # Lemmatize the tokens\n#     lemmatizer = WordNetLemmatizer()\n#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n\n    # Join the lemmatized tokens back into a string\n    #processed_text = ' '.join(text)\n\n    return text\n\n# Apply the processing function to the 'Post' column\nif 'text' in df.columns:\n    df['text'] = df['text'].apply(lambda x: process_text(str(x)))\nelse:\n    print(\"Warning: 'text' column not found in the DataFrame.\")\n\n# Display the first few rows of the processed DataFrame\nprint(df.head())","metadata":{"_uuid":"e7472282-fad9-4a3b-8537-e4e0bc364b52","_cell_guid":"b2233559-5b2a-43c5-918e-3915bbcd8131","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:40.529941Z","iopub.execute_input":"2024-08-10T15:15:40.530230Z","iopub.status.idle":"2024-08-10T15:15:41.788565Z","shell.execute_reply.started":"2024-08-10T15:15:40.530194Z","shell.execute_reply":"2024-08-10T15:15:41.787643Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                                                text  label\n0  dear american teens question dutch person hear...      0\n1  nothing look forward lifei dont many reasons k...      1\n2  music recommendations im looking expand playli...      0\n3  im done trying feel betterthe reason im still ...      1\n4  worried  year old girl subject domestic physic...      1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create label mapping\nunique_labels = df['label'].unique()\nlabel_dict = {label: i for i, label in enumerate(unique_labels)}\nnum_labels = len(unique_labels)\nprint(\"Label mapping:\", label_dict)","metadata":{"_uuid":"4b31edf6-207b-417d-8d8f-96ba329a7a6a","_cell_guid":"009624d5-e81c-4321-8152-7c9cc55f54ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:41.789720Z","iopub.execute_input":"2024-08-10T15:15:41.789989Z","iopub.status.idle":"2024-08-10T15:15:41.800263Z","shell.execute_reply.started":"2024-08-10T15:15:41.789966Z","shell.execute_reply":"2024-08-10T15:15:41.799474Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Label mapping: {0: 0, 1: 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# BERT Model Setup\nmodel_name = 'FacebookAI/xlm-roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name,force_download=True)\nbert_model = AutoModelForSequenceClassification.from_pretrained(model_name,force_download=True)","metadata":{"_uuid":"0b0c33a3-b04e-45cb-8e43-413617451a4b","_cell_guid":"502d6cd4-1ebf-4c30-8ad6-695ae8db6c61","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:41.801590Z","iopub.execute_input":"2024-08-10T15:15:41.801858Z","iopub.status.idle":"2024-08-10T15:15:51.952963Z","shell.execute_reply.started":"2024-08-10T15:15:41.801835Z","shell.execute_reply":"2024-08-10T15:15:51.952233Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e6b643ddc4426691160bac0952cb4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a8ad26e824b4aa3a12ad7c9d98b4982"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f0797f4dc945aa814651f889870e96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88e8f73543f4f9c90d2b0c9ac9c13bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"594c29df851a492c9ea94802c4a90d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73fbaa648f94de89739162e1a8fc6da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02311e98d384816984cf6f583336906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"704e1b3ce0e04753b1e76c8b08cbfb95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67defd2e35ae4c42a3fef39dc3444d78"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, label_dict):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.label_dict = label_dict\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = str(self.data.iloc[idx]['text'])\n        label = self.data.iloc[idx]['label']\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(self.label_dict[label], dtype=torch.long)\n        }","metadata":{"_uuid":"41b66e33-b874-4903-8ac1-9acf3382efe7","_cell_guid":"65525dbb-fd5a-4bbe-a212-8b6d70d94d37","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:51.954198Z","iopub.execute_input":"2024-08-10T15:15:51.954680Z","iopub.status.idle":"2024-08-10T15:15:51.962642Z","shell.execute_reply.started":"2024-08-10T15:15:51.954653Z","shell.execute_reply":"2024-08-10T15:15:51.961740Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Prepare data\nfull_dataset = CustomDataset(df, tokenizer, max_len=128, label_dict=label_dict)\n\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=4)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = nn.DataParallel(bert_model, device_ids=[0, 1])\nmodel.to(device)\nprint(device)","metadata":{"_uuid":"0a1404ba-357c-40dc-8796-a7c87c08ea80","_cell_guid":"60bbbf8d-8946-4f4f-af46-f0aa679285de","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:51.963824Z","iopub.execute_input":"2024-08-10T15:15:51.964431Z","iopub.status.idle":"2024-08-10T15:15:52.697052Z","shell.execute_reply.started":"2024-08-10T15:15:51.964400Z","shell.execute_reply":"2024-08-10T15:15:52.696077Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5)\n\nnum_epochs = 5\n\n# Lists to store metrics\ntrain_losses = []\nval_losses = []\naccuracies = []\nprecisions = []\nrecalls = []\nf1_scores = []\nprint(\"starting training\")\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        # Ensure loss is a scalar\n        if loss.dim() > 0:\n            loss = loss.mean()\n\n        total_train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    model.eval()\n    val_predictions = []\n    val_true_labels = []\n    total_val_loss = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n\n            if loss.dim() > 0:\n                loss = loss.mean()\n\n            total_val_loss += loss.item()\n            _, preds = torch.max(outputs.logits, dim=1)\n\n            val_predictions.extend(preds.cpu().tolist())\n            val_true_labels.extend(labels.cpu().tolist())\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n\n    accuracy = accuracy_score(val_true_labels, val_predictions)\n    precision = precision_score(val_true_labels, val_predictions, average='weighted')\n    recall = recall_score(val_true_labels, val_predictions, average='weighted')\n    f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n\n    accuracies.append(accuracy)\n    precisions.append(precision)\n    recalls.append(recall)\n    f1_scores.append(f1)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Training Loss: {avg_train_loss:.4f}\")\n    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(\"--------------------\")","metadata":{"_uuid":"f31c785d-a595-4cc6-b908-09fc1d9c87e4","_cell_guid":"19e530d5-1dae-4abb-9149-8ef7a53103d6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-10T15:15:52.699514Z","iopub.execute_input":"2024-08-10T15:15:52.699819Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"starting training\n","output_type":"stream"},{"name":"stderr","text":"2024-08-10 15:15:59.306540: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-10 15:15:59.306640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-10 15:15:59.705025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\nTraining Loss: 0.2158\nValidation Loss: 0.1260\nAccuracy: 0.9523\nPrecision: 0.9523\nRecall: 0.9523\nF1 Score: 0.9523\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5\nTraining Loss: 0.1100\nValidation Loss: 0.1306\nAccuracy: 0.9559\nPrecision: 0.9567\nRecall: 0.9559\nF1 Score: 0.9558\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5\nTraining Loss: 0.0792\nValidation Loss: 0.1042\nAccuracy: 0.9618\nPrecision: 0.9618\nRecall: 0.9618\nF1 Score: 0.9618\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5\nTraining Loss: 0.0586\nValidation Loss: 0.1231\nAccuracy: 0.9603\nPrecision: 0.9603\nRecall: 0.9603\nF1 Score: 0.9603\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]}]}